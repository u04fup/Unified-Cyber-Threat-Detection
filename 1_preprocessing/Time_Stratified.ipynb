{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================================================\n",
    "#   USER CONFIGURATION SECTION\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. PATH SETTINGS\n",
    "# ------------------------------------------------------------------------------\n",
    "INPUT_FILE = \"/path/to/creditcard.csv\"\n",
    "SAVE_DIR = \"/path/to/output_directory\"\n",
    "\n",
    "# 2. COLUMN SETTINGS\n",
    "# ------------------------------------------------------------------------------\n",
    "LABEL_COL = \"Class\"  # 1 = Fraud, 0 = Genuine\n",
    "TIME_COL = \"Time\"    # Numerical timestamp column\n",
    "\n",
    "# 3. SPLIT STRATEGY\n",
    "# ------------------------------------------------------------------------------\n",
    "# Ratio of fraud samples to allocate to the Test set (e.g., 0.2 = 20%)\n",
    "# The script finds the timestamp that splits the fraud cases 80/20 \n",
    "# and uses that timestamp to split the entire dataset.\n",
    "TEST_FRAUD_RATIO = 0.2 \n",
    "\n",
    "# 4. OUTPUT FILENAMES\n",
    "# ------------------------------------------------------------------------------\n",
    "OUT_TRAIN = \"train_creditcard_timesplit.csv\"\n",
    "OUT_TEST = \"test_creditcard_timesplit.csv\"\n",
    "\n",
    "# ==============================================================================\n",
    "#   MAIN PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    # --- 1. Load Data ---\n",
    "    print(f\"=== Loading Data ===\")\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        raise FileNotFoundError(f\"File not found: {INPUT_FILE}\")\n",
    "\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"Initial Rows: {len(df):,}, Cols: {len(df.columns)}\")\n",
    "\n",
    "    # --- 2. Validation & Cleaning ---\n",
    "    if LABEL_COL not in df.columns or TIME_COL not in df.columns:\n",
    "        raise ValueError(f\"Missing required columns: {LABEL_COL} or {TIME_COL}\")\n",
    "\n",
    "    # Fill NaNs with 0 (Standard for this dataset if any exist)\n",
    "    n_null = df.isnull().sum().sum()\n",
    "    if n_null > 0:\n",
    "        print(f\"Warning: Filled {n_null} NaN values with 0.\")\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "    # --- 3. Time-Based Stratified Splitting ---\n",
    "    print(\"\\n=== Executing Time-Anchored Split ===\")\n",
    "    \n",
    "    # A. Sort entire dataset by time\n",
    "    df = df.sort_values(by=TIME_COL).reset_index(drop=True)\n",
    "    \n",
    "    # B. Isolate Fraud samples\n",
    "    fraud_df = df[df[LABEL_COL] == 1]\n",
    "    total_frauds = len(fraud_df)\n",
    "    print(f\"Total Fraud Samples: {total_frauds}\")\n",
    "\n",
    "    if total_frauds > 0:\n",
    "        # C. Calculate split point based on Fraud count\n",
    "        n_test_fraud = int(total_frauds * TEST_FRAUD_RATIO)\n",
    "        \n",
    "        # Ensure at least 1 fraud sample in test if frauds exist\n",
    "        if n_test_fraud == 0: \n",
    "            n_test_fraud = 1\n",
    "            \n",
    "        # D. Find the specific timestamp that separates the last 20% of frauds\n",
    "        # Get the last N fraud samples\n",
    "        test_fraud_subset = fraud_df.tail(n_test_fraud)\n",
    "        # The split timestamp is the time of the *first* transaction in this subset\n",
    "        split_timestamp = test_fraud_subset[TIME_COL].min()\n",
    "        \n",
    "        print(f\"Targeting {n_test_fraud} fraud samples for Test set.\")\n",
    "        print(f\"Calculated Split Timestamp: {split_timestamp}\")\n",
    "\n",
    "        # E. Split the WHOLE dataset based on this timestamp\n",
    "        train_df = df[df[TIME_COL] < split_timestamp]\n",
    "        test_df = df[df[TIME_COL] >= split_timestamp]\n",
    "        \n",
    "    else:\n",
    "        # Fallback if dataset has no fraud labels (rare edge case)\n",
    "        print(\"Warning: No fraud labels found. Doing simple sequential split.\")\n",
    "        split_idx = int(len(df) * (1 - TEST_FRAUD_RATIO))\n",
    "        train_df = df.iloc[:split_idx]\n",
    "        test_df = df.iloc[split_idx:]\n",
    "\n",
    "    # --- 4. Statistics & Save ---\n",
    "    print(f\"\\nTrain set: {len(train_df):,} rows\")\n",
    "    print(f\"Test set:  {len(test_df):,} rows\")\n",
    "    \n",
    "    # Calculate Fraud Ratios\n",
    "    train_fraud_rate = train_df[LABEL_COL].mean()\n",
    "    test_fraud_rate = test_df[LABEL_COL].mean()\n",
    "    \n",
    "    print(f\"Fraud Rate (Train): {train_fraud_rate:.4%} ({train_df[LABEL_COL].sum()} cases)\")\n",
    "    print(f\"Fraud Rate (Test):  {test_fraud_rate:.4%} ({test_df[LABEL_COL].sum()} cases)\")\n",
    "\n",
    "    train_path = os.path.join(SAVE_DIR, OUT_TRAIN)\n",
    "    test_path = os.path.join(SAVE_DIR, OUT_TEST)\n",
    "\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "\n",
    "    print(\"\\n=== Processing Complete ===\")\n",
    "    print(f\"Saved Train: {train_path}\")\n",
    "    print(f\"Saved Test:  {test_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_env)",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
